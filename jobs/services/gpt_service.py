import json
import logging
from django.conf import settings
from typing import Dict, Any

logger = logging.getLogger(__name__)

# OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì•ˆì „ import
try:
    import openai
    OPENAI_AVAILABLE = True
    logger.info("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
except ImportError:
    OPENAI_AVAILABLE = False
    logger.error("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


class GPTService:
    """OpenAI GPT APIë¥¼ ì‚¬ìš©í•œ ê°€ì´ë“œë¼ì¸ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.use_fallback = True
        self.client = None
        
        # OpenAI ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        if not OPENAI_AVAILABLE:
            logger.error("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return
            
        # API í‚¤ í™•ì¸
        self.api_key = getattr(settings, 'OPENAI_API_KEY', '')
        
        # API í‚¤ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
        if self.api_key:
            logger.info(f"ğŸ”‘ API í‚¤ í™•ì¸ë¨:")
            logger.info(f"   - ê¸¸ì´: {len(self.api_key)}ì")
            logger.info(f"   - ì‹œì‘: {self.api_key[:20]}...")
            logger.info(f"   - ë: ...{self.api_key[-10:]}")
            logger.info(f"   - ì „ì²´: {self.api_key}")  # ë””ë²„ê¹…ìš© ì „ì²´ í‚¤ ì¶œë ¥
        else:
            logger.error("âŒ API í‚¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
        if not self.api_key or self.api_key.startswith('sk-your'):
            logger.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì˜ OPENAI_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return
            
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (0.28.1 ë²„ì „ìš©)
        try:
            # OpenAI 0.28.1 ë°©ì‹: ì „ì—­ API í‚¤ ì„¤ì •
            logger.info("OpenAI 0.28.1 ë°©ì‹ìœ¼ë¡œ ì´ˆê¸°í™” ì‹œë„...")
            openai.api_key = self.api_key
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸ - ì˜¬ë°”ë¥¸ ëª¨ë¸ëª…ìœ¼ë¡œ
            logger.info("OpenAI API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
            test_response = openai.ChatCompletion.create(
                model="gpt-4o-mini",  # ì¡´ì¬í•˜ëŠ” ëª¨ë¸ëª… ì‚¬ìš©
                messages=[{"role": "user", "content": "í…ŒìŠ¤íŠ¸"}],
                max_tokens=5
            )
            
            self.use_fallback = False
            self.model_name = "gpt-4o-mini"
            logger.info("âœ… OpenAI API ì—°ê²° ì„±ê³µ! ì‹¤ì œ GPTë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
        except Exception as e:
            logger.warning(f"gpt-4o-mini ì‹¤íŒ¨: {e}")
            try:
                # gpt-3.5-turboë¡œ ì¬ì‹œë„
                logger.info("gpt-3.5-turboë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸...")
                test_response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": "í…ŒìŠ¤íŠ¸"}],
                    max_tokens=5
                )
                
                self.use_fallback = False
                self.model_name = "gpt-3.5-turbo"
                logger.info("âœ… OpenAI API ì—°ê²° ì„±ê³µ! (gpt-3.5-turbo)")
                
            except Exception as e2:
                logger.error(f"âŒ ëª¨ë“  ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:")
                logger.error(f"   gpt-4o-mini: {e}")
                logger.error(f"   gpt-3.5-turbo: {e2}")
                logger.error("ê¸°ë³¸ ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self.use_fallback = True
    
    def generate_summary(self, guideline_text: str = None) -> Dict[str, Any]:
        """
        ê°€ì´ë“œë¼ì¸ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë°˜í™˜
        """
        # Fallback ì‚¬ìš©
        if self.use_fallback:
            logger.warning("ğŸ”„ ì‹¤ì œ GPT APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ë”ë¯¸ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return self._get_default_summary()
            
        try:
            # ê¸°ë³¸ ê°€ì´ë“œë¼ì¸ í…ìŠ¤íŠ¸
            if not guideline_text:
                guideline_text = """
                ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ê°€ì´ë“œë¼ì¸
                
                1. ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬
                - ëª¨ë“  ì½”ë“œëŠ” ì½”ë“œ ë¦¬ë·°ë¥¼ ê±°ì³ì•¼ í•©ë‹ˆë‹¤
                - ë¦°í„°ì™€ í¬ë§¤í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ëœ ì½”ë”© ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•©ë‹ˆë‹¤
                - ë³€ìˆ˜ëª…ê³¼ í•¨ìˆ˜ëª…ì€ ëª…í™•í•˜ê³  ì˜ë¯¸ ìˆê²Œ ì‘ì„±í•©ë‹ˆë‹¤
                - ë³µì¡í•œ ë¡œì§ì—ëŠ” ì¶©ë¶„í•œ ì£¼ì„ì„ ì‘ì„±í•©ë‹ˆë‹¤
                
                2. í…ŒìŠ¤íŒ…
                - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ëŠ” ìµœì†Œ 80% ì´ìƒì„ ìœ ì§€í•©ë‹ˆë‹¤
                - í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì‹œìŠ¤í…œ ì „ì²´ ë™ì‘ì„ ê²€ì¦í•©ë‹ˆë‹¤
                - CI/CD íŒŒì´í”„ë¼ì¸ì—ì„œ ìë™í™”ëœ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤
                - í…ŒìŠ¤íŠ¸ ì½”ë“œë„ í”„ë¡œë•ì…˜ ì½”ë“œì™€ ë™ì¼í•œ í’ˆì§ˆì„ ìœ ì§€í•©ë‹ˆë‹¤
                
                3. ë¬¸ì„œí™”
                - API ë¬¸ì„œëŠ” ìë™ìœ¼ë¡œ ìƒì„±ë˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤
                - README íŒŒì¼ì„ ìµœì‹  ìƒíƒœë¡œ ìœ ì§€í•©ë‹ˆë‹¤
                - ì•„í‚¤í…ì²˜ ê²°ì •ì‚¬í•­ì€ ADR(Architecture Decision Record)ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤
                - ìš´ì˜ ê°€ì´ë“œì™€ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë¬¸ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤
                
                4. ë³´ì•ˆ
                - ë¯¼ê°í•œ ì •ë³´ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤
                - ì •ê¸°ì ìœ¼ë¡œ ë³´ì•ˆ ì·¨ì•½ì  ìŠ¤ìº”ì„ ì‹¤í–‰í•©ë‹ˆë‹¤
                - ì¸ì¦ê³¼ ê¶Œí•œ ê´€ë¦¬ë¥¼ ì² ì €íˆ í•©ë‹ˆë‹¤
                - HTTPSë¥¼ í•„ìˆ˜ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤
                """
            
            prompt = f"""
            ë‹¤ìŒ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ê°€ì´ë“œë¼ì¸ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.
            
            ê°€ì´ë“œë¼ì¸:
            {guideline_text}
            
            ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
            {{
                "title": "ê°€ì´ë“œë¼ì¸ì˜ ì œëª©",
                "content": "ê°€ì´ë“œë¼ì¸ì˜ ì „ì²´ì ì¸ ìš”ì•½ (2-3ë¬¸ì¥)",
                "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 1", "í•µì‹¬ í¬ì¸íŠ¸ 2", "í•µì‹¬ í¬ì¸íŠ¸ 3"],
                "word_count": ë‹¨ì–´ìˆ˜
            }}
            
            JSON í˜•ì‹ë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            """
            
            logger.info("ğŸ¤– ì‹¤ì œ GPT APIë¡œ ìš”ì•½ ìƒì„± ì‹œì‘...")
            
            # OpenAI 0.28.1 ë°©ì‹ ì‚¬ìš©
            response = openai.ChatCompletion.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            content = response.choices[0].message.content.strip()
            logger.info(f"âœ… GPT API ì‘ë‹µ ì„±ê³µ! (ê¸¸ì´: {len(content)}ì)")
            logger.info(f"ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {content[:100]}...")
            
            # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            try:
                # ```jsonê³¼ ``` ì œê±°
                if content.startswith('```json'):
                    content = content[7:]  # ```json ì œê±°
                if content.startswith('```'):
                    content = content[3:]   # ``` ì œê±°
                if content.endswith('```'):
                    content = content[:-3]  # ëì˜ ``` ì œê±°
                
                content = content.strip()
                summary_data = json.loads(content)
                logger.info("ğŸ‰ ì‹¤ì œ GPTê°€ ìƒì„±í•œ ìš”ì•½ ì™„ë£Œ!")
                
                # GPT ì‘ë‹µì„ì„ í‘œì‹œí•˜ê¸° ìœ„í•´ ë©”íƒ€ ì •ë³´ ì¶”ê°€
                summary_data['_source'] = 'openai_gpt'
                summary_data['_model'] = self.model_name
                
                return summary_data
            except json.JSONDecodeError as e:
                logger.error(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
                logger.error(f"ì •ì œëœ ì‘ë‹µ: {content[:200]}...")
                return self._get_default_summary()
                
        except Exception as e:
            logger.error(f"âŒ GPT ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._get_default_summary()
    
    def generate_checklist(self, summary: Dict[str, Any]) -> Dict[str, Any]:
        """
        ìš”ì•½ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±
        """
        # Fallback ì‚¬ìš©
        if self.use_fallback:
            logger.warning("ğŸ”„ ì‹¤ì œ GPT APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ë”ë¯¸ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return self._get_default_checklist()
            
        try:
            prompt = f"""
            ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ê°œë°œìë“¤ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
            
            ìš”ì•½:
            ì œëª©: {summary.get('title', '')}
            ë‚´ìš©: {summary.get('content', '')}
            í•µì‹¬ í¬ì¸íŠ¸: {', '.join(summary.get('key_points', []))}
            
            ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
            {{
                "categories": [
                    {{
                        "name": "ì¹´í…Œê³ ë¦¬ëª…",
                        "items": [
                            {{
                                "id": 1,
                                "text": "ì²´í¬í•  ë‚´ìš© (ì§ˆë¬¸ í˜•íƒœ)",
                                "required": true
                            }}
                        ]
                    }}
                ],
                "total_items": ì „ì²´_í•­ëª©_ìˆ˜,
                "required_items": í•„ìˆ˜_í•­ëª©_ìˆ˜
            }}
            
            ì¹´í…Œê³ ë¦¬ëŠ” 4-5ê°œ, ê° ì¹´í…Œê³ ë¦¬ë‹¹ 3-5ê°œ í•­ëª©ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
            JSON í˜•ì‹ë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            """
            
            logger.info("ğŸ¤– ì‹¤ì œ GPT APIë¡œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì‹œì‘...")
            
            # OpenAI 0.28.1 ë°©ì‹ ì‚¬ìš©
            response = openai.ChatCompletion.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.2,
                max_tokens=1500
            )
            
            content = response.choices[0].message.content.strip()
            logger.info(f"âœ… GPT API ì‘ë‹µ ì„±ê³µ! (ê¸¸ì´: {len(content)}ì)")
            logger.info(f"ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {content[:100]}...")
            
            # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            try:
                # ```jsonê³¼ ``` ì œê±°
                if content.startswith('```json'):
                    content = content[7:]  # ```json ì œê±°
                if content.startswith('```'):
                    content = content[3:]   # ``` ì œê±°
                if content.endswith('```'):
                    content = content[:-3]  # ëì˜ ``` ì œê±°
                
                content = content.strip()
                checklist_data = json.loads(content)
                logger.info("ğŸ‰ ì‹¤ì œ GPTê°€ ìƒì„±í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì™„ë£Œ!")
                
                # GPT ì‘ë‹µì„ì„ í‘œì‹œí•˜ê¸° ìœ„í•´ ë©”íƒ€ ì •ë³´ ì¶”ê°€
                checklist_data['_source'] = 'openai_gpt'
                checklist_data['_model'] = self.model_name
                
                return checklist_data
            except json.JSONDecodeError as e:
                logger.error(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
                logger.error(f"ì •ì œëœ ì‘ë‹µ: {content[:200]}...")
                return self._get_default_checklist()
                
        except Exception as e:
            logger.error(f"âŒ GPT ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._get_default_checklist()
    
    def _get_default_summary(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ìš”ì•½ ë°˜í™˜ (ë”ë¯¸ ë°ì´í„°)"""
        return {
            "title": "ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ê°€ì´ë“œë¼ì¸ ìš”ì•½",
            "content": "ê°€ì´ë“œë¼ì¸ì€ ì½”ë“œ í’ˆì§ˆ, í…ŒìŠ¤íŒ…, ë¬¸ì„œí™”, ë³´ì•ˆ ë“± ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì˜ í•µì‹¬ ì›ì¹™ë“¤ì„ ë‹¤ë£¹ë‹ˆë‹¤.",
            "key_points": [
                "ì½”ë“œ ë¦¬ë·° í•„ìˆ˜",
                "í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 80% ì´ìƒ", 
                "API ë¬¸ì„œí™” ìë™í™”"
            ],
            "word_count": 150,
            "_source": "fallback_dummy",
            "_model": "dummy_data"
        }
    
    def _get_default_checklist(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ë”ë¯¸ ë°ì´í„°)"""
        return {
            "categories": [
                {
                    "name": "ì½”ë“œ í’ˆì§ˆ",
                    "items": [
                        {"id": 1, "text": "ì½”ë“œ ë¦¬ë·°ê°€ ì™„ë£Œë˜ì—ˆëŠ”ê°€?", "required": True},
                        {"id": 2, "text": "ë¦°í„° ê·œì¹™ì„ ì¤€ìˆ˜í•˜ì˜€ëŠ”ê°€?", "required": True},
                        {"id": 3, "text": "ë³€ìˆ˜ëª…ì´ ëª…í™•í•˜ê²Œ ì‘ì„±ë˜ì—ˆëŠ”ê°€?", "required": False}
                    ]
                },
                {
                    "name": "í…ŒìŠ¤íŒ…", 
                    "items": [
                        {"id": 4, "text": "ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ê°€ ì‘ì„±ë˜ì—ˆëŠ”ê°€?", "required": True},
                        {"id": 5, "text": "í†µí•© í…ŒìŠ¤íŠ¸ê°€ ìˆ˜í–‰ë˜ì—ˆëŠ”ê°€?", "required": True}
                    ]
                },
                {
                    "name": "ë¬¸ì„œí™”",
                    "items": [
                        {"id": 6, "text": "API ë¬¸ì„œê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆëŠ”ê°€?", "required": True},
                        {"id": 7, "text": "README íŒŒì¼ì´ ìµœì‹ ì¸ê°€?", "required": False}
                    ]
                }
            ],
            "total_items": 7,
            "required_items": 5,
            "_source": "fallback_dummy",
            "_model": "dummy_data"
        }